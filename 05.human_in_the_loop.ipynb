{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "728426b4",
   "metadata": {},
   "source": [
    "# Add human-in-the-loop controls\n",
    "- Doc: https://langchain-ai.github.io/langgraph/tutorials/get-started/4-human-in-the-loop/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ac9c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# API-KEY 읽어오기\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c8e19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# 모델 초기화\n",
    "llm = init_chat_model(\"google_genai:gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d4cfc6",
   "metadata": {},
   "source": [
    "## 1. Add the human_assistance tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52487fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_core.tools import tool\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "\n",
    "# 에이전트의 상태 정의 클래스\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# 상태 기반 워크플로우 생성\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# 챗봇이 인간의 개입을 요청할 때 호출됨 (도구)\n",
    "@tool\n",
    "def human_assistance(query: str) -> str:\n",
    "    \"\"\"Request assistance from a human.\"\"\"\n",
    "    # interrupt: 워크플로우를 일시 중지하고 인간의 응답을 기다림\n",
    "    human_response = interrupt({\"query\": query})\n",
    "    # 인간의 응답에서 data 반환\n",
    "    return human_response[\"data\"]\n",
    "\n",
    "# 웹 검색을 도구\n",
    "tool = TavilySearch(max_results=2)\n",
    "# 도구 리스트\n",
    "tools = [tool, human_assistance]\n",
    "\n",
    "# LLM이 도구 호출 여부 판단\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# chatbot 노드 함수\n",
    "def chatbot(state: State):\n",
    "    message = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # 병렬 도구 호출 비활성화: 인터럽트 후 툴 중복 호출 방지\n",
    "    assert len(message.tool_calls) <= 1\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "# 워크플로우에 chatbot 노드 추가\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# tool 노드 워크플로우에 추가\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "# 조건부 라우팅: tools로 이동하거나 END로 이동 (종료)\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "# tools 노드 실행 후 chatbot 노드로 다시 이동 (도구 결과 처리)\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "# 워크플로우 시작점에서 chatbot 노드로 이동\n",
    "graph_builder.add_edge(START, \"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7fe11a",
   "metadata": {},
   "source": [
    "## 2. Compile the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e245843",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()\n",
    "# 워크플로우 컴파일, 실행 가능한 워크플로우 생성.\n",
    "# memory checkpointer 사용\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34231807",
   "metadata": {},
   "source": [
    "## 3. Visualize the graph (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0c2cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    # 워크플로우 그래프를 이미지로 시각화하여 출력\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d13a170",
   "metadata": {},
   "source": [
    "## 4. Prompt the chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b656b6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = (\n",
    "    \"AI agent를 만드는 데 전문가의 도움이 필요해. \"\n",
    "    \"도움을 요청해 줘\"\n",
    ")\n",
    "# 대화 세션을 구분하기 위한 설정\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# 워크플로우를 스트리밍 모드로 실행 (사용자 입력 처리)\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config=config,\n",
    "    stream_mode=\"values\",  # values: 각 노드가 실행을 마친 후 결과 스트리밍\n",
    ")\n",
    "# 각 event의 마지막 메시지 출력\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1127bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지정된 config의 워크플로우 상태 확인\n",
    "snapshot = graph.get_state(config)\n",
    "# snapshot.next: 다음에 실행될 노드\n",
    "# 출력: ['tools'] (human_assistance 호출로 인해 tools 노드에서 일시 정지 상태)\n",
    "snapshot.next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae68ade",
   "metadata": {},
   "source": [
    "## 5. Resume execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498e34cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인간의 응답을 가상으로 생성\n",
    "human_response = (\n",
    "    \"저희 전문가들이 도와드리겠습니다!\"\n",
    "    \" 에이전트를 구축하려면 LangGraph를 확인해 보세요.\"\n",
    "    \" 단순한 자율 에이전트보다 훨씬 안정적이고 확장성이 뛰어납니다.\"\n",
    ")\n",
    "\n",
    "# Command 객체의 resume에 인간 응답 저장\n",
    "human_command = Command(resume={\"data\": human_response})\n",
    "\n",
    "# 워크플로우를 스트리밍 모드로 실행 (인간 응답 처리)\n",
    "events = graph.stream(\n",
    "    human_command,\n",
    "    config,\n",
    "    stream_mode=\"values\",  # values: 각 노드가 실행을 마친 후 결과를 스트리밍\n",
    ")\n",
    "# 각 event의 마지막 메시지 출력\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69efeaa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
