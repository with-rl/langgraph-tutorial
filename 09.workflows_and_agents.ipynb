{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97fe1219",
   "metadata": {},
   "source": [
    "# Workflows and Agents\n",
    "- Doc: https://langchain-ai.github.io/langgraph/tutorials/workflows/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4200eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# API-KEY 읽어오기\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d20a82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# 모델 초기화\n",
    "llm = init_chat_model(\"google_genai:gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bb510e",
   "metadata": {},
   "source": [
    "## Building Blocks: The Augmented LLM\n",
    "- Doc: https://langchain-ai.github.io/langgraph/tutorials/workflows/#building-blocks-the-augmented-llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40e4d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# 에이전트의 상태 정의 클래스\n",
    "class SearchQuery(BaseModel):\n",
    "    # 웹 검색 쿼리\n",
    "    search_query: str = Field(None, description=\"Query that is optimized web search.\")\n",
    "    # 사용자의 요청과 관련된 이유\n",
    "    justification: str = Field(\n",
    "        None, description=\"Why this query is relevant to the user's request.\"\n",
    "    )\n",
    "\n",
    "\n",
    "# 상태 기반 워크플로우 생성\n",
    "structured_llm = llm.with_structured_output(SearchQuery)\n",
    "\n",
    "# LLM을 호출하여 사용자 입력에 대한 응답 생성.\n",
    "output = structured_llm.invoke(\"수학 성적이 좋은 학생은 과학 성적도 좋을 수 있어?\")\n",
    "\n",
    "# 결과 확인\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2094b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 간단한 곱셈 도구(multiply)\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    return a * b\n",
    "\n",
    "# LLM이 도구 호출 여부 판단\n",
    "llm_with_tools = llm.bind_tools([multiply])\n",
    "\n",
    "# 사용자 입력: 곱셈 요청(\"2 x 3 = ?\")\n",
    "msg = llm_with_tools.invoke(\"각각 8개씩 들어있는 사과 상자가 7개 있어, 모두 몇 개의 사과가 있는지 알려줘.\")\n",
    "\n",
    "# 도구 호출 정보 확인\n",
    "print(f\"도구 호출 정보: {msg.tool_calls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd852504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 실행\n",
    "if msg.tool_calls[0]['name'] == 'multiply':\n",
    "    result = multiply(**msg.tool_calls[0]['args'])\n",
    "    print(f\"도구 실행 결과: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67d05d9",
   "metadata": {},
   "source": [
    "## Prompt chaining\n",
    "- Doc: https://langchain-ai.github.io/langgraph/tutorials/workflows/#prompt-chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0516f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "# 에이전트의 상태 정의 클래스\n",
    "class State(TypedDict):\n",
    "    topic: str           # 주제 (사용자 입력)\n",
    "    joke: str            # 초기 농담\n",
    "    improved_joke: str   # 개선된 농담\n",
    "    final_joke: str      # 최종적으로 다듬어진 농담\n",
    "\n",
    "\n",
    "# 첫 번째 LLM 호출: 최초 농담 생성 함수\n",
    "def generate_joke(state: State):\n",
    "    \"\"\"First LLM call to generate initial joke\"\"\"\n",
    "    # 주제(topic)를 기반으로 LLM에게 농담 생성 요청\n",
    "    msg = llm.invoke(f\"Write a short joke about {state['topic']}\")\n",
    "     # 생성된 농담을 상태에 저장\n",
    "    return {\"joke\": msg.content}\n",
    "\n",
    "\n",
    "# 농담에 펀치라인이 있는지 확인하는 게이트 함수 (펀치라인: 농담에서 가장 재미있고 결정적인 부분)\n",
    "def check_punchline(state: State):\n",
    "    \"\"\"Gate function to check if the joke has a punchline\"\"\"\n",
    "\n",
    "    # 농담에 \"?\" 또는 \"!\"가 포함되어 있으면 펀치라인이 있다고 간주\n",
    "    if \"?\" in state[\"joke\"] or \"!\" in state[\"joke\"]:\n",
    "        return \"Pass\"  # 펀치라인이 있으면 통과\n",
    "    return \"Fail\"      # 펀치라인이 없으면 실패\n",
    "\n",
    "\n",
    "# 두 번째 LLM 호출: 농담를 더 재미있게 개선하는 함수\n",
    "def improve_joke(state: State):\n",
    "    \"\"\"Second LLM call to improve the joke\"\"\"\n",
    "\n",
    "    # 기존 농담에 말장난(wordplay)을 추가하여 개선 요청\n",
    "    msg = llm.invoke(f\"Make this joke funnier by adding wordplay: {state['joke']}\")\n",
    "    # 개선된 농담를 상태에 저장\n",
    "    return {\"improved_joke\": msg.content}\n",
    "\n",
    "\n",
    "# 세 번째 LLM 호출: 농담에 반전을 추가하는 함수\n",
    "def polish_joke(state: State):\n",
    "    \"\"\"Third LLM call for final polish\"\"\"\n",
    "\n",
    "    # 개선된 농담에 놀라운 반전(twist)을 추가 요청\n",
    "    msg = llm.invoke(f\"Add a surprising twist to this joke: {state['improved_joke']}\")\n",
    "    # 최종 다듬어진 농담를 상태에 저장\n",
    "    return {\"final_joke\": msg.content}\n",
    "\n",
    "\n",
    "# 상태 기반 워크플로우 생성\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# 노드를 워크플로우에 추가\n",
    "workflow.add_node(\"generate_joke\", generate_joke)\n",
    "workflow.add_node(\"improve_joke\", improve_joke)\n",
    "workflow.add_node(\"polish_joke\", polish_joke)\n",
    "\n",
    "# 시작 지점에서 초기 농담 생성으로 이동\n",
    "workflow.add_edge(START, \"generate_joke\")  \n",
    "# 펀치라인 확인 {실패: 종료, 통과: 개선}\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate_joke\",\n",
    "    check_punchline,\n",
    "    {\"Fail\": END, \"Pass\": \"improve_joke\"}\n",
    ")\n",
    "# 개선 후 반전 추가 단계로 이동\n",
    "workflow.add_edge(\"improve_joke\", \"polish_joke\") \n",
    "# 다듬기 후 워크플로우 종료\n",
    "workflow.add_edge(\"polish_joke\", END)\n",
    "\n",
    "# 워크플로우 컴파일, 실행 가능한 워크플로우 생성.\n",
    "chain = workflow.compile()\n",
    "\n",
    "# 워크플로우 그래프를 이미지로 시각화하여 출력\n",
    "display(Image(chain.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36474123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 워크플로우 실행 및 결과 출력\n",
    "state = chain.invoke({\"topic\": \"장화 신은 고양이\"})\n",
    "print(\"Initial joke:\")\n",
    "print(state[\"joke\"])\n",
    "print(\"\\n\", \"=\" * 80,\"\\n\")\n",
    "if \"improved_joke\" in state:\n",
    "    print(\"Improved joke:\")\n",
    "    print(state[\"improved_joke\"])\n",
    "    print(\"\\n\", \"=\" * 80,\"\\n\")\n",
    "\n",
    "    print(\"Final joke:\")\n",
    "    print(state[\"final_joke\"])\n",
    "else:\n",
    "    print(\"Joke failed quality gate - no punchline detected!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed99c08d",
   "metadata": {},
   "source": [
    "## Parallelization\n",
    "- Doc: https://langchain-ai.github.io/langgraph/tutorials/workflows/#parallelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6364fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에이전트의 상태 정의 클래스\n",
    "class State(TypedDict):\n",
    "    topic: str            # 생성할 콘텐츠의 주제\n",
    "    joke: str             # 주제에 기반한 농담\n",
    "    story: str            # 주제에 기반한 이야기\n",
    "    poem: str             # 주제에 기반한 시\n",
    "    combined_output: str  # 농담, 이야기, 시를 결합한 최종 출력\n",
    "\n",
    "\n",
    "# 첫 번째 LLM 호출: 주제에 맞는 농담을 생성하는 함수\n",
    "def call_llm_1(state: State):\n",
    "    \"\"\"First LLM call to generate initial joke\"\"\"\n",
    "\n",
    "    # 주제(topic)를 기반으로 LLM에게 농담 생성 요청\n",
    "    msg = llm.invoke(f\"Write a joke about {state['topic']}\")\n",
    "    # 생성된 농담을 상태에 저장\n",
    "    return {\"joke\": msg.content}\n",
    "\n",
    "\n",
    "# 두 번째 LLM 호출: 주제에 맞는 이야기를 생성하는 함수\n",
    "def call_llm_2(state: State):\n",
    "    \"\"\"Second LLM call to generate story\"\"\"\n",
    "\n",
    "    # 주제(topic)를 기반으로 LLM에게 이야기 생성 요청\n",
    "    msg = llm.invoke(f\"Write a story about {state['topic']}\")\n",
    "    # 생성된 이야기를 상태에 저장\n",
    "    return {\"story\": msg.content}\n",
    "\n",
    "\n",
    "# 세 번째 LLM 호출: 주제에 맞는 시를 생성하는 함수\n",
    "def call_llm_3(state: State):\n",
    "    \"\"\"Third LLM call to generate poem\"\"\"\n",
    "\n",
    "    # 주제(topic)를 기반으로 LLM에게 시 생성 요청\n",
    "    msg = llm.invoke(f\"Write a poem about {state['topic']}\")\n",
    "    # 생성된 시를 상태에 저장\n",
    "    return {\"poem\": msg.content}\n",
    "\n",
    "\n",
    "# 농담, 이야기, 시를 하나의 출력으로 모으는 함수\n",
    "def aggregator(state: State):\n",
    "    \"\"\"Combine the joke and story into a single output\"\"\"\n",
    "\n",
    "    # 주제를 포함한 헤더와 함께 농담, 이야기, 시를 결합\n",
    "    combined = f\"Here's a story, joke, and poem about {state['topic']}!\\n\\n\"\n",
    "    combined += f\"STORY:\\n{state['story']}\\n\\n\"\n",
    "    combined += f\"JOKE:\\n{state['joke']}\\n\\n\"\n",
    "    combined += f\"POEM:\\n{state['poem']}\"\n",
    "    # 결합된 결과를 상태에 저장\n",
    "    return {\"combined_output\": combined}\n",
    "\n",
    "\n",
    "# 상태 기반 워크플로우 생성\n",
    "parallel_builder = StateGraph(State)\n",
    "\n",
    "# 노드를 워크플로우에 추가\n",
    "parallel_builder.add_node(\"call_llm_1\", call_llm_1)  # 농담 생성 노드\n",
    "parallel_builder.add_node(\"call_llm_2\", call_llm_2)  # 이야기 생성 노드\n",
    "parallel_builder.add_node(\"call_llm_3\", call_llm_3)  # 시 생성 노드\n",
    "parallel_builder.add_node(\"aggregator\", aggregator)  # 결과 결합 노드\n",
    "\n",
    "# 노드 간 엣지(연결)를 추가하여 병렬 처리 구조 정의\n",
    "parallel_builder.add_edge(START, \"call_llm_1\")  # 시작 지점에서 농담 생성 노드로 이동\n",
    "parallel_builder.add_edge(START, \"call_llm_2\")  # 시작 지점에서 이야기 생성 노드로 이동\n",
    "parallel_builder.add_edge(START, \"call_llm_3\")  # 시작 지점에서 시 생성 노드로 이동\n",
    "parallel_builder.add_edge(\"call_llm_1\", \"aggregator\")  # 농담 생성 후 aggregator로 이동\n",
    "parallel_builder.add_edge(\"call_llm_2\", \"aggregator\")  # 이야기 생성 후 aggregator로 이동\n",
    "parallel_builder.add_edge(\"call_llm_3\", \"aggregator\")  # 시 생성 후 aggregator로 이동\n",
    "parallel_builder.add_edge(\"aggregator\", END)           # aggregator에서 워크플로우 종료\n",
    "\n",
    "# 워크플로우 컴파일\n",
    "parallel_workflow = parallel_builder.compile()\n",
    "\n",
    "# 워크플로우 그래프를 이미지로 시각화하여 출력\n",
    "display(Image(parallel_workflow.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60da6ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 워크플로우 실행\n",
    "events = parallel_workflow.stream({\"topic\": \"호랑이 담배\"})\n",
    "# 이벤트 출력\n",
    "final_event = None\n",
    "for event in events:\n",
    "    print(\"=\" * 80)\n",
    "    print(event)\n",
    "    final_event = event  # 마지막 이벤트 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363782d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 결과 출력\n",
    "print(final_event[\"aggregator\"][\"combined_output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e80f6be",
   "metadata": {},
   "source": [
    "## Routing\n",
    "- Doc: https://langchain-ai.github.io/langgraph/tutorials/workflows/#routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be364b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Literal\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "\n",
    "# 라우팅위 위한 구조화된 출력 스키마 정의 클래스\n",
    "class Route(BaseModel):\n",
    "    # 다음 단계로 라우팅할 경로\n",
    "    step: Literal[\"poem\", \"story\", \"joke\"] = Field(\n",
    "        None, description=\"The next step in the routing process\"\n",
    "    )\n",
    "\n",
    "# LLM이 구조화된 출력(Route 스키마)을 하도록\n",
    "router = llm.with_structured_output(Route)\n",
    "\n",
    "# 에이전트의 상태 정의 클래스\n",
    "class State(TypedDict):\n",
    "    input: str     # 사용자의 입력 요청\n",
    "    decision: str  # 라우터가 결정한 다음 단계 (poem, story, joke)\n",
    "    output: str    # 최종 생성된 출력 (농담, 이야기, 시)\n",
    "\n",
    "\n",
    "# 주제에 맞는 이야기를 생성하는 함수\n",
    "def llm_call_story(state: State):\n",
    "    \"\"\"Write a story\"\"\"\n",
    "    # 입력을 기반으로 LLM에게 이야기 생성 요청\n",
    "    result = llm.invoke(state[\"input\"])\n",
    "    # 생성된 이야기를 상태의 output에 저장\n",
    "    return {\"output\": result.content}\n",
    "\n",
    "# 주제에 맞는 농담을 생성하는 함수\n",
    "def llm_call_joke(state: State):\n",
    "    \"\"\"Write a joke\"\"\"\n",
    "    # 입력을 기반으로 LLM에게 농담 생성 요청\n",
    "    result = llm.invoke(state[\"input\"])\n",
    "    # 생성된 농담을 상태의 output에 저장\n",
    "    return {\"output\": result.content}\n",
    "\n",
    "# 주제에 맞는 시를 생성하는 함수\n",
    "def llm_call_poem(state: State):\n",
    "    \"\"\"Write a poem\"\"\"\n",
    "    # 입력을 기반으로 LLM에게 시 생성 요청\n",
    "    result = llm.invoke(state[\"input\"])\n",
    "    # 생성된 시를 상태의 output에 저장\n",
    "    return {\"output\": result.content}\n",
    "\n",
    "# 입력을 적절한 노드(story, joke, poem)로 라우팅하는 함수\n",
    "def llm_call_router(state: State):\n",
    "    \"\"\"Route the input to the appropriate node\"\"\"\n",
    "\n",
    "    # LLM에게 입력을 분석하고 라우팅 결정을 요청 (구조화된 출력)\n",
    "    decision = router.invoke(\n",
    "        [\n",
    "            SystemMessage(\n",
    "                content=\"Route the input to story, joke, or poem based on the user's request.\"\n",
    "            ),\n",
    "            HumanMessage(content=state[\"input\"]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return {\"decision\": decision.step}\n",
    "\n",
    "\n",
    "# 라우팅 결정을 기반으로 다음 노드를 선택\n",
    "def route_decision(state: State):\n",
    "    if state[\"decision\"] == \"story\":\n",
    "        return \"llm_call_story\"  # 이야기 생성 노드로 이동\n",
    "    elif state[\"decision\"] == \"joke\":\n",
    "        return \"llm_call_joke\"  # 농담 생성 노드로 이동\n",
    "    elif state[\"decision\"] == \"poem\":\n",
    "        return \"llm_call_poem\"  # 시 생성 노드로 이동\n",
    "\n",
    "\n",
    "# 상태 기반 워크플로우 생성\n",
    "router_builder = StateGraph(State)\n",
    "\n",
    "# 노드를 워크플로우에 추가\n",
    "router_builder.add_node(\"llm_call_story\", llm_call_story)            # 이야기 생성 노드\n",
    "router_builder.add_node(\"llm_call_joke\", llm_call_joke)            # 농담 생성 노드\n",
    "router_builder.add_node(\"llm_call_poem\", llm_call_poem)            # 시 생성 노드\n",
    "router_builder.add_node(\"llm_call_router\", llm_call_router)  # 라우팅 결정 노드\n",
    "\n",
    "# 노드 간 엣지(연결)를 추가하여 워크플로우 구조 정의\n",
    "router_builder.add_edge(START, \"llm_call_router\")  # 시작 지점에서 라우팅 노드로 이동\n",
    "router_builder.add_conditional_edges(              # route_decision 결과에 따라 다음 노드 선택\n",
    "    \"llm_call_router\",\n",
    "    route_decision,\n",
    "    {\n",
    "        \"llm_call_story\": \"llm_call_story\",\n",
    "        \"llm_call_joke\": \"llm_call_joke\",\n",
    "        \"llm_call_poem\": \"llm_call_poem\",\n",
    "    },\n",
    ")\n",
    "router_builder.add_edge(\"llm_call_story\", END)  # 이야기 생성 후 워크플로우 종료\n",
    "router_builder.add_edge(\"llm_call_joke\", END)  # 농담 생성 후 워크플로우 종료\n",
    "router_builder.add_edge(\"llm_call_poem\", END)  # 시 생성 후 워크플로우 종료\n",
    "\n",
    "# 워크플로우 컴파일\n",
    "router_workflow = router_builder.compile()\n",
    "\n",
    "# 워크플로우 그래프를 이미지로 시각화하여 출력\n",
    "display(Image(router_workflow.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ab80e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 워크플로우 실행\n",
    "events = router_workflow.stream({\"input\": \"고양이 관련한 농담을 만들어줘\"})\n",
    "# 이벤트 출력\n",
    "final_event = None\n",
    "for event in events:\n",
    "    print(\"=\" * 80)\n",
    "    print(event)\n",
    "    final_event = event  # 마지막 이벤트 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322175ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 결과 출력\n",
    "print(final_event[\"llm_call_joke\"][\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bfa3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 워크플로우 실행\n",
    "events = router_workflow.stream({\"input\": \"고양이 관련한 이야기를 만들어줘\"})\n",
    "# 이벤트 출력\n",
    "final_event = None\n",
    "for event in events:\n",
    "    print(\"=\" * 80)\n",
    "    print(event)\n",
    "    final_event = event  # 마지막 이벤트 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf3db71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 결과 출력\n",
    "print(final_event[\"llm_call_story\"][\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34eda03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 워크플로우 실행\n",
    "events = router_workflow.stream({\"input\": \"고양이 관련한 시를 만들어줘\"})\n",
    "# 이벤트 출력\n",
    "final_event = None\n",
    "for event in events:\n",
    "    print(\"=\" * 80)\n",
    "    print(event)\n",
    "    final_event = event  # 마지막 이벤트 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24106ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 결과 출력\n",
    "print(final_event[\"llm_call_poem\"][\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5287e71a",
   "metadata": {},
   "source": [
    "## Orchestrator-Worker\n",
    "- Doc: https://langchain-ai.github.io/langgraph/tutorials/workflows/#orchestrator-worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070f96b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List\n",
    "\n",
    "\n",
    "# 보고서 섹션의 구조를 정의하는 클래스\n",
    "class Section(BaseModel):\n",
    "    name: str = Field(         # 보고서 섹션의 제목\n",
    "        description=\"Name for this section of the report.\",\n",
    "    )\n",
    "    description: str = Field(  # 섹션에서 다룰 주요 주제와 개념의 개요\n",
    "        description=\"Brief overview of the main topics and concepts to be covered in this section.\",\n",
    "    )\n",
    "\n",
    "\n",
    "# 여러 섹션을 포함하는 보고서 구조를 정의하는 클래스\n",
    "class Sections(BaseModel):\n",
    "    sections: List[Section] = Field(  # 보고서의 섹션 목록\n",
    "        description=\"Sections of the report.\",\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM이 구조화된 출력(Sections 스키마)을 하도록\n",
    "planner = llm.with_structured_output(Sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4397fb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from langgraph.types import Send\n",
    "\n",
    "\n",
    "# 에이전트의 상태 정의 클래스\n",
    "class State(TypedDict):\n",
    "    topic: str                      # 보고서의 주제\n",
    "    sections: list[Section]         # 보고서의 섹션 목록\n",
    "    completed_sections: Annotated[  # 완성된 섹션 목록 (operator.add로 추가)\n",
    "        list, operator.add\n",
    "    ]\n",
    "    final_report: str               # 최종 보고서 내용\n",
    "\n",
    "\n",
    "# 개별 섹션 생성 워커의 상태 정의 클래스\n",
    "class WorkerState(TypedDict):\n",
    "    section: Section                # 처리할 개별 섹션\n",
    "\n",
    "\n",
    "# 보고서 계획을 생성하는 오케스트레이터 함수\n",
    "def orchestrator(state: State):\n",
    "    \"\"\"Orchestrator that generates a plan for the report\"\"\"\n",
    "\n",
    "    # Sections 스키마 생성 요청\n",
    "    report_sections = planner.invoke(\n",
    "        [\n",
    "            # 보고서 계획 생성 요청\n",
    "            SystemMessage(content=\"Generate a plan for the report.\"),\n",
    "            # 주제 제공\n",
    "            HumanMessage(content=f\"Here is the report topic: {state['topic']}\"),\n",
    "        ]\n",
    "    )\n",
    "    # 생성된 섹션 계획을 상태에 저장\n",
    "    return {\"sections\": report_sections.sections}\n",
    "\n",
    "\n",
    "# 보고서의 개별 섹션을 작성하는 워커 함수\n",
    "def llm_call(state: WorkerState):\n",
    "    \"\"\"Worker writes a section of the report\"\"\"\n",
    "\n",
    "    # Generate section\n",
    "    # LLM을 통해 섹션 이름과 설명을 기반으로 섹션 내용 생성\n",
    "    section = llm.invoke(\n",
    "        [\n",
    "            SystemMessage(\n",
    "                content=\"Write a report section following the provided name and description.\"\n",
    "                        \" Include no preamble for each section.\"\n",
    "                        \" Use markdown formatting.\"\n",
    "                # 섹션 작성 지침: 서문 없이 마크다운 형식으로 작성\n",
    "            ),\n",
    "            HumanMessage(\n",
    "                content=f\"Here is the section name: {state['section'].name} and description: {state['section'].description}\"\n",
    "                # 섹션 작성 지침: 서문 없이 마크다운 형식으로 작성\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # 작성된 섹션을 completed_sections에 저장\n",
    "    return {\"completed_sections\": [section.content]}\n",
    "\n",
    "\n",
    "# 모든 섹션을 합쳐 최종 보고서를 생성하는 함수\n",
    "def synthesizer(state: State):\n",
    "    \"\"\"Synthesize full report from sections\"\"\"\n",
    "\n",
    "    # 완성된 섹션 리스트 가져오기\n",
    "    completed_sections = state[\"completed_sections\"]\n",
    "\n",
    "    # 섹션들을 연결하여 문자열로 포맷\n",
    "    completed_report_sections = \"\\n\\n---\\n\\n\".join(completed_sections)\n",
    "\n",
    "    # 최종 보고서를 상태에 저장\n",
    "    return {\"final_report\": completed_report_sections}\n",
    "\n",
    "\n",
    "# 조건부 엣지 함수: 보고서 계획의 각 섹션에 워커를 할당하는 함수\n",
    "def assign_workers(state: State):\n",
    "    \"\"\"Assign a worker to each section in the plan\"\"\"\n",
    "\n",
    "    # 섹션마다 병렬로 llm_call 워커를 실행하도록 Send API 사용\n",
    "    return [Send(\"llm_call\", {\"section\": s}) for s in state[\"sections\"]]\n",
    "\n",
    "\n",
    "# 워크플로우 그래프 구축\n",
    "orchestrator_worker_builder = StateGraph(State)\n",
    "\n",
    "# 노드를 워크플로우에 추가\n",
    "orchestrator_worker_builder.add_node(\"orchestrator\", orchestrator)  # 보고서 계획 생성 노드\n",
    "orchestrator_worker_builder.add_node(\"llm_call\", llm_call)          # 섹션 작성 노드\n",
    "orchestrator_worker_builder.add_node(\"synthesizer\", synthesizer)    # 최종 보고서 통합 노드\n",
    "\n",
    "# 노드 간 엣지(연결)를 추가하여 워크플로우 구조 정의\n",
    "orchestrator_worker_builder.add_edge(START, \"orchestrator\")      # 시작 지점에서 오케스트레이터로 이동\n",
    "orchestrator_worker_builder.add_conditional_edges(               # 오케스트레이터에서 섹션별로 병렬 이동\n",
    "    \"orchestrator\", assign_workers, [\"llm_call\"]\n",
    ")\n",
    "orchestrator_worker_builder.add_edge(\"llm_call\", \"synthesizer\")  # 섹션 작성 후 합성 노드로 이동\n",
    "orchestrator_worker_builder.add_edge(\"synthesizer\", END)         # 합성 후 워크플로우 종료\n",
    "\n",
    "# 워크플로우 컴파일\n",
    "orchestrator_worker = orchestrator_worker_builder.compile()\n",
    "\n",
    "# 워크플로우 그래프를 이미지로 시각화하여 출력\n",
    "display(Image(orchestrator_worker.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575f8f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 워크플로우 실행\n",
    "events = orchestrator_worker.stream({\"topic\": \"LLM scaling laws에 관련한 보고서를 작성해줘\"})\n",
    "# 이벤트 출력\n",
    "final_event = None\n",
    "for event in events:\n",
    "    print(\"=\" * 80)\n",
    "    print(event)\n",
    "    final_event = event  # 마지막 이벤트 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5719c4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 보고서를 마크다운 형식으로 출력\n",
    "from IPython.display import Markdown\n",
    "Markdown(final_event[\"synthesizer\"][\"final_report\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14193b6c",
   "metadata": {},
   "source": [
    "## Evaluator-optimizer\n",
    "- Doc: https://langchain-ai.github.io/langgraph/tutorials/workflows/#evaluator-optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6642a23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에이전트의 상태 정의 클래스\n",
    "class State(TypedDict):\n",
    "    topic: str        # 농담의 주제\n",
    "    joke: str         # 생성된 농담\n",
    "    feedback: str     # 농담 개선을 위한 피드백\n",
    "    funny_or_not: str # 농담이 재미있는지 여부 (\"funny\" 또는 \"not funny\")\n",
    "\n",
    "\n",
    "# 평가를 위한 구조화된 출력 스키마 정의\n",
    "class Feedback(BaseModel):\n",
    "    grade: Literal[\"funny\", \"not funny\"] = Field(  # 농담의 재미 여부 판단\n",
    "        description=\"Decide if the joke is funny or not.\",\n",
    "    )\n",
    "    feedback: str = Field(                         # 재미없을 경우 개선 피드백\n",
    "        description=\"If the joke is not funny, provide feedback on how to improve it.\",\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM이 구조화된 출력(Feedback 스키마)을 하도록\n",
    "evaluator = llm.with_structured_output(Feedback)\n",
    "\n",
    "\n",
    "# LLM이 주제에 맞는 농담을 생성하는 함수\n",
    "def llm_call_generator(state: State):\n",
    "    \"\"\"LLM generates a joke\"\"\"\n",
    "\n",
    "    if state.get(\"feedback\"):  # 피드백이 있는 경우, 피드백을 반영하여 농담 생성\n",
    "        msg = llm.invoke(\n",
    "            f\"Write a joke about {state['topic']} but take into account the feedback: {state['feedback']}\"\n",
    "        )\n",
    "    else:                      # 피드백이 없는 경우, 주제만으로 농담 생성\n",
    "        msg = llm.invoke(f\"Write a joke about {state['topic']}\")\n",
    "    # 생성된 농담을 상태에 저장\n",
    "    return {\"joke\": msg.content}\n",
    "\n",
    "# LLM이 농담을 평가하는 함수\n",
    "def llm_call_evaluator(state: State):\n",
    "    \"\"\"LLM evaluates the joke\"\"\"\n",
    "\n",
    "    # 농담을 평가하여 재미 여부와 피드백 생성\n",
    "    grade = evaluator.invoke(f\"Grade the joke {state['joke']}\")\n",
    "    # 평가 결과(재미 여부)와 피드백을 상태에 저장\n",
    "    return {\"funny_or_not\": grade.grade, \"feedback\": grade.feedback}\n",
    "\n",
    "\n",
    "# 조건부 엣지 함수: 평가 결과에 따라 농담 생성기로 돌아가거나 종료하는 함수\n",
    "def route_joke(state: State):\n",
    "    \"\"\"Route back to joke generator or end based upon feedback from the evaluator\"\"\"\n",
    "    if state[\"funny_or_not\"] == \"funny\":        # 농담이 재미있다면 워크플로우 종료\n",
    "        return \"Accepted\"\n",
    "    elif state[\"funny_or_not\"] == \"not funny\":  # 농담이 재미없다면 피드백과 함께 생성기로 돌아감\n",
    "        return \"Rejected + Feedback\"\n",
    "\n",
    "\n",
    "# 워크플로우 그래프 구축\n",
    "optimizer_builder = StateGraph(State)\n",
    "\n",
    "# 노드를 워크플로우에 추가\n",
    "optimizer_builder.add_node(\"llm_call_generator\", llm_call_generator)  # 농담 생성 노드\n",
    "optimizer_builder.add_node(\"llm_call_evaluator\", llm_call_evaluator)  # 농 KY 평가 노드\n",
    "\n",
    "# 노드 간 엣지(연결)를 추가하여 워크플로우 구조 정의\n",
    "optimizer_builder.add_edge(START, \"llm_call_generator\")  # 시작 지점에서 농담 생성 노드로 이동\n",
    "optimizer_builder.add_edge(\"llm_call_generator\", \"llm_call_evaluator\")  # 생성 후 평가 노드로 이동\n",
    "optimizer_builder.add_conditional_edges(\n",
    "    \"llm_call_evaluator\",\n",
    "    route_joke,  # route_joke 함수가 반환한 값에 따라 다음 단계 결정\n",
    "    {\n",
    "        \"Accepted\": END,                              # 재미있으면 종료\n",
    "        \"Rejected + Feedback\": \"llm_call_generator\",  # 재미없으면 피드백과 함께 생성기로 돌아감\n",
    "    },\n",
    ")\n",
    "\n",
    "# 워크플로우 컴파일\n",
    "optimizer_workflow = optimizer_builder.compile()\n",
    "\n",
    "# 워크플로우 그래프를 이미지로 시각화하여 표시\n",
    "display(Image(optimizer_workflow.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf76858a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 워크플로우 실행\n",
    "events = optimizer_workflow.stream({\"topic\": \"고양이\"})\n",
    "# 이벤트 출력\n",
    "final_event = None\n",
    "for event in events:\n",
    "    print(\"=\" * 80)\n",
    "    print(event)\n",
    "    if \"llm_call_generator\" in event:\n",
    "        final_event = event  # llm_call_generator의 마지막 이벤트 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d233389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 결과 출력\n",
    "print(final_event[\"llm_call_generator\"][\"joke\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0c79a1",
   "metadata": {},
   "source": [
    "# Agent\n",
    "- Doc: https://langchain-ai.github.io/langgraph/tutorials/workflows/#agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4200828c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "# 두 정수의 곱을 계산 하는 도구\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "# 두 정수의 합을 계산 하는 도구\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "# 두 정수의 나누기를 계산 하는 도구\n",
    "@tool\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divide a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a / b\n",
    "\n",
    "\n",
    "# 사용 가능한 도구 목록\n",
    "tools = [add, multiply, divide]\n",
    "# 도구 이름을 키로 한 딕셔너리 생성\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "# LLM이 도구 호출 여부 판단\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e708bf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState, START, END\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, ToolMessage\n",
    "\n",
    "\n",
    "# LLM이 도구 호출 여부를 결정하는 함수\n",
    "def llm_call(state: MessagesState):\n",
    "    \"\"\"LLM decides whether to call a tool or not\"\"\"\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            llm_with_tools.invoke(\n",
    "                [\n",
    "                    SystemMessage(\n",
    "                        content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\"\n",
    "                    )\n",
    "                ]\n",
    "                + state[\"messages\"]\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "# 도구 호출을 수행하는 함수\n",
    "def tool_node(state: dict):\n",
    "    \"\"\"Performs the tool call\"\"\"\n",
    "\n",
    "    result = []\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        tool = tools_by_name[tool_call[\"name\"]]       # 호출된 도구 이름으로 도구 선택\n",
    "        observation = tool.invoke(tool_call[\"args\"])  # 도구 실행\n",
    "        # 도구 호출 결과로 ToolMessage 생성\n",
    "        result.append(ToolMessage(content=observation, tool_call_id=tool_call[\"id\"]))\n",
    "    return {\"messages\": result}  # 도구 호출 결과를 메시지로 반환\n",
    "\n",
    "\n",
    "# 조건부 엣지 함수: LLM이 도구를 호출했는지 여부에 따라 다음 단계를 결정하는 함수\n",
    "def should_continue(state: MessagesState) -> Literal[\"environment\", END]:\n",
    "    \"\"\"Decide if we should continue the loop or stop based upon whether the LLM made a tool call\"\"\"\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:  # LLM이 도구를 호출했으면 tool_node 노드로 이동\n",
    "        return \"Action\"\n",
    "    return END                   # 도구 호출이 없으면 워크플로우 종료\n",
    "\n",
    "\n",
    "# 워크플로우 그래프 구축\n",
    "agent_builder = StateGraph(MessagesState)\n",
    "\n",
    "# 노드를 워크플로우에 추가\n",
    "agent_builder.add_node(\"llm_call\", llm_call)      # LLM 호출 노드\n",
    "agent_builder.add_node(\"environment\", tool_node)  # 도구 실행 노드\n",
    "\n",
    "# 노드 간 엣지(연결)를 추가하여 워크플로우 구조 정의\n",
    "agent_builder.add_edge(START, \"llm_call\")         # 시작 지점에서 LLM 호출 노드로 이동\n",
    "agent_builder.add_conditional_edges(\n",
    "    \"llm_call\",\n",
    "    should_continue, # should_continue 함수의 반환값에 따라 다음 노드 결정\n",
    "    {\n",
    "        \"Action\": \"environment\",  # 도구 호출 시 environment로 이동\n",
    "        END: END,                 # 도구 호출 없으면 종료\n",
    "    },\n",
    ")\n",
    "agent_builder.add_edge(\"environment\", \"llm_call\")  # 도구 실행 후 다시 LLM 호출로 이동\n",
    "\n",
    "# 워크플로우 컴파일\n",
    "agent = agent_builder.compile()\n",
    "\n",
    "# 워크플로우 그래프를 이미지로 시각화하여 출력\n",
    "display(Image(agent.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061f09e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 워크플로우 실행\n",
    "user_input = \"사과 6개와 배 5개가 들어있는 상자가 5개일 때, 과일의 총 개수를 구하시오.\"\n",
    "events = agent.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]})\n",
    "for event in events:\n",
    "    for value in event.values():\n",
    "        value[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91c5abe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
