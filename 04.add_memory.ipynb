{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "675ed543",
   "metadata": {},
   "source": [
    "# Add memory\n",
    "- Doc: https://langchain-ai.github.io/langgraph/tutorials/get-started/3-add-memory/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3033b5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# API-KEY 읽어오기\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d460757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# 모델 초기화\n",
    "llm = init_chat_model(\"google_genai:gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443f53cf",
   "metadata": {},
   "source": [
    "## 1. Create a MemorySaver checkpointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107f15b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# MemorySaver: 워크플로우의 상태를 메모리에 저장\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed063a0",
   "metadata": {},
   "source": [
    "## 2. Compile the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ca1bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "# 에이전트의 상태 정의 클래스\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# 상태 기반 워크플로우 생성\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# 웹 검색을 도구\n",
    "tool = TavilySearch(max_results=2)\n",
    "# 도구 리스트\n",
    "tools = [tool]\n",
    "\n",
    "# LLM이 도구 호출 여부 판단\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# chatbot 노드 함수\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "# 워크플로우에 chatbot 노드 추가\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# LangGraph의 prebuilt ToolNode를 사용\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "# tool 노드 워크플로우에 추가\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "# 조건부 라우팅: tools로 이동하거나 END로 이동 (종료)\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,  # LangGraph의 prebuilt 함수\n",
    "                      # 마지막 메시지에 `tool_calls`가 있는지 확인\n",
    ")\n",
    "\n",
    "# tools 노드 실행 후 chatbot 노드로 다시 이동 (도구 결과 처리)\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "# 워크플로우 시작점에서 chatbot 노드로 이동\n",
    "graph_builder.add_edge(START, \"chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6330d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 워크플로우 컴파일, 실행 가능한 워크플로우 생성.\n",
    "# memory checkpointer 사용\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841d086b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    # 워크플로우 그래프를 이미지로 시각화하여 출력\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76fbab5",
   "metadata": {},
   "source": [
    "## 3. Interact with your chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdff9d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대화 세션을 구분하기 위한 설정\n",
    "# thread_id는 대화의 고유 식별자로, MemorySaver가 대화 기록을 저장/로드하는 데 사용\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "def stream_graph_updates(user_input: str):\n",
    "    # 워크플로우를 스트리밍 모드로 실행 (사용자 입력 처리)\n",
    "    events = graph.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "        config=config\n",
    "    )\n",
    "    for event in events:\n",
    "        for value in event.values():\n",
    "            # 이벤트의 마지막 메시지 출력\n",
    "            value[\"messages\"][-1].pretty_print()\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")  # 사용자 입력 받기\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:  # 종료 조건\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        # 워크플로우 실행\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # 오류 발생시 기본 질문으로 대체\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffac36e",
   "metadata": {},
   "source": [
    "## 4. Ask a follow up question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2f0bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 thread_id 사용 (이전 대화 세션)\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "def stream_graph_updates(user_input: str):\n",
    "    # 워크플로우를 스트리밍 모드로 실행 (사용자 입력 처리)\n",
    "    events = graph.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "        config=config\n",
    "    )\n",
    "    for event in events:\n",
    "        for value in event.values():\n",
    "            # 이벤트의 마지막 메시지 출력\n",
    "            value[\"messages\"][-1].pretty_print()\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")  # 사용자 입력 받기\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:  # 종료 조건\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        # 워크플로우 실행\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # 오류 발생시 기본 질문으로 대체\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3a7b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 thread_id 사용 (새로운 대화 세션)\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "def stream_graph_updates(user_input: str):\n",
    "    # 워크플로우를 스트리밍 모드로 실행 (사용자 입력 처리)\n",
    "    events = graph.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "        config=config\n",
    "    )\n",
    "    for event in events:\n",
    "        for value in event.values():\n",
    "            # 이벤트의 마지막 메시지 출력\n",
    "            value[\"messages\"][-1].pretty_print()\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")  # 사용자 입력 받기\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:  # 종료 조건\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        # 워크플로우 실행\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # 오류 발생시 기본 질문으로 대체\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ce70d0",
   "metadata": {},
   "source": [
    "## 5. Inspect the state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658bab35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# thread_id: 1\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# config에 해당하는 워크플로우의 상태 스냅샷 조회\n",
    "snapshot = graph.get_state(config)\n",
    "\n",
    "print(\"-\" * 20, \"messages\", \"-\" * 20)\n",
    "for v in snapshot.values['messages']:\n",
    "    print(v)\n",
    "print(\"-\" * 20, \"config\", \"-\" * 20)\n",
    "print(snapshot.config)\n",
    "print(\"-\" * 20, \"next\", \"-\" * 20)\n",
    "print(snapshot.next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f13de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# thread_id: 2\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# config에 해당하는 워크플로우의 상태 스냅샷 조회\n",
    "snapshot = graph.get_state(config)\n",
    "\n",
    "print(\"-\" * 20, \"messages\", \"-\" * 20)\n",
    "for v in snapshot.values['messages']:\n",
    "    print(v)\n",
    "print(\"-\" * 20, \"config\", \"-\" * 20)\n",
    "print(snapshot.config)\n",
    "print(\"-\" * 20, \"next\", \"-\" * 20)\n",
    "print(snapshot.next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15053bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
