{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecae97b2",
   "metadata": {},
   "source": [
    "# LangGraph quickstart\n",
    "- Doc: https://langchain-ai.github.io/langgraph/agents/agents/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2c9205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# API-KEY 읽어오기\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cf6bbb",
   "metadata": {},
   "source": [
    "## 2. Create an agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd7089a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# 도시의 날씨 정보를 반환하는 함수\n",
    "def get_weather(city: str) -> str:  \n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"{city} 날씨는 항상 화창합니다!\"\n",
    "\n",
    "# ReAct 에이전트 생성\n",
    "agent = create_react_agent(\n",
    "    model=\"google_genai:gemini-2.5-flash\",  # 사용할 LLM 모델 지정\n",
    "    tools=[get_weather],                    # 에이전트가 사용할 도구 목록\n",
    "    prompt=\"You are a helpful assistant\"    # 에이전트의 역할과 동작을 정의하는 프롬프트\n",
    ")\n",
    "\n",
    "# 에이전트 실행\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"서울 날씨 어때?\"}]},  # 사용자 메시지 입력\n",
    ")\n",
    "# 결과 출력\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca07b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 단계의 메시지 출력\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3de227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에이전트 실행\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"오눌 주요 뉴스가 뭐야?\"}]},  # 사용자 메시지 입력\n",
    ")\n",
    "# 결과 출력\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88350ae7",
   "metadata": {},
   "source": [
    "## 3. Configure an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4d2431",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# 채팅 모델 초기화\n",
    "model = init_chat_model(\n",
    "    model=\"google_genai:gemini-2.5-flash\",  # 사용할 LLM 모델 지정\n",
    "    temperature=0                           # 출력의 다양성 조절\n",
    "                                            # 낮은 Temperature: 확률 분포를 더 날카롭게 만듬, 예측 가능하고 일관된 출력 생성\n",
    "                                            # 높은 Temperature: 확률 분포를 더 평평하게 만듬, 창의적이고 다양한 출력 생성\n",
    ")\n",
    "\n",
    "# ReAct 에이전트 생성\n",
    "agent = create_react_agent(\n",
    "    model=model,          # 사용할 LLM 모델 객체 지정\n",
    "    tools=[get_weather],  # 에이전트가 사용할 도구 목록\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63b9389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에이전트 실행\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"서울 날씨 어때?\"}]},  # 사용자 메시지 입력\n",
    ")\n",
    "# 각 단계의 메시지 출력\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3491b5ce",
   "metadata": {},
   "source": [
    "## 4. Add a custom prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1296c561",
   "metadata": {},
   "source": [
    "### Static prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb157104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# ReAct 에이전트 생성\n",
    "agent = create_react_agent(\n",
    "    model=\"google_genai:gemini-2.5-flash\",              # 사용할 LLM 모델 지정\n",
    "    tools=[get_weather],                                # 에이전트가 사용할 도구 목록\n",
    "    prompt=\"Never answer questions about the weather.\"  # 에이전트의 역할과 동작을 정의하는 정적 프롬프트\n",
    ")\n",
    "\n",
    "# 에이전트 실행\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"서울 날씨 어때?\"}]}\n",
    ")\n",
    "# 각 단계의 메시지 출력\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89b2e4e",
   "metadata": {},
   "source": [
    "### Dynamic prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb91f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AnyMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.prebuilt.chat_agent_executor import AgentState\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# 에이전트의 프롬프트 생성 함수\n",
    "def prompt(state: AgentState, config: RunnableConfig) -> list[AnyMessage]:  \n",
    "    # config에서 사용자 이름을 추출\n",
    "    user_name = config[\"configurable\"].get(\"user_name\")\n",
    "    # 시스템 메시지 생성: 사용자 이름을 포함\n",
    "    system_msg = f\"You are a helpful assistant. Address the user as {user_name}.\"\n",
    "    # 시스템 메시지와 기존 상태의 메시지를 결합하여 반환\n",
    "    return [{\"role\": \"system\", \"content\": system_msg}] + state[\"messages\"]\n",
    "\n",
    "# ReAct 에이전트 생성\n",
    "agent = create_react_agent(\n",
    "    model=\"google_genai:gemini-2.5-flash\",  # 사용할 LLM 모델 지정\n",
    "    tools=[get_weather],                    # 에이전트가 사용할 도구 목록\n",
    "    prompt=prompt                           # 함수를 이용한 동적 프롬프트 생성\n",
    ")\n",
    "\n",
    "# 에이전트 실행\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\":  \"서울 날씨 어때?\"}]},\n",
    "    # 에이전트 실행을 위한 설정 정보\n",
    "    config={\"configurable\": {\"user_name\": \"홍길동\"}}\n",
    ")\n",
    "# 각 단계의 메시지 출력\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e281c21",
   "metadata": {},
   "source": [
    "## 5. Add memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd4e960",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "# 에이전트의 상태를 메모리에 저장 (프로그램이 종료되면 사라짐)\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "# ReAct 에이전트 생성\n",
    "agent = create_react_agent(\n",
    "    model=\"google_genai:gemini-2.5-flash\",  # 사용할 LLM 모델 지정\n",
    "    tools=[get_weather],                    # 에이전트가 사용할 도구 목록\n",
    "    checkpointer=checkpointer               # 에이전트의 상태를 저장하는 기능 추가\n",
    ")\n",
    "\n",
    "# 에이전트 실행을 위한 설정 정보\n",
    "# 'thread_id'는 대화의 고유 식별자 역할\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# 에이전트 실행 (서울)\n",
    "seoul_response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"서울 날쌔 어때?\"}]},\n",
    "    config  \n",
    ")\n",
    "# 에이전트 실행 (부산)\n",
    "pusan_response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"부산 날씨 어때?\"}]},\n",
    "    config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c91c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 단계의 메시지 출력\n",
    "for message in seoul_response['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9161afec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 단계의 메시지 출력\n",
    "for message in pusan_response['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d32897",
   "metadata": {},
   "source": [
    "## 6. Configure structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ec7041",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# 날씨 응답을 구조화하기 위한 모델\n",
    "class WeatherResponse(BaseModel):\n",
    "    conditions: str\n",
    "\n",
    "# ReAct 에이전트 생성\n",
    "agent = create_react_agent(\n",
    "    model=\"google_genai:gemini-2.5-flash\",  # 사용할 LLM 모델 지정\n",
    "    tools=[get_weather],                    # 에이전트가 사용할 도구 목록\n",
    "    response_format=WeatherResponse         # 응답을 WeatherResponse 형식으로 구조화\n",
    ")\n",
    "\n",
    "# 에이전트 실행\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\":  \"서울 날씨 어때?\"}]}\n",
    ")\n",
    "\n",
    "# 구조화된 응답 추출\n",
    "response[\"structured_response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030853a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 단계의 메시지 출력\n",
    "for message in response['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88102569",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, Annotated\n",
    "from pydantic import BaseModel\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# 날씨 응답을 구조화하기 위한 모델\n",
    "class WeatherResponse(BaseModel):\n",
    "    conditions: Annotated[\n",
    "        # 허용되는 문자열 값들\n",
    "        Literal[\"맑음\", \"흐림\", \"비\", \"눈\"],\n",
    "        # 필드에 대한 설명 (LLM이 이 정보를 사용해서 응답을 구조화함)\n",
    "        \"Includes only concise and essential current weather conditions.\"\n",
    "    ]\n",
    "\n",
    "# ReAct 에이전트 생성\n",
    "agent = create_react_agent(\n",
    "    model=\"google_genai:gemini-2.5-flash\",  # 사용할 LLM 모델 지정\n",
    "    tools=[get_weather],                    # 에이전트가 사용할 도구 목록\n",
    "    response_format=WeatherResponse         # 응답을 WeatherResponse 형식으로 구조화\n",
    ")\n",
    "\n",
    "# 에이전트 실행\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\":  \"서울 날씨 어때?\"}]}\n",
    ")\n",
    "\n",
    "# 구조화된 응답 추출\n",
    "response[\"structured_response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51552108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 단계의 메시지 출력\n",
    "for message in response['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e23a78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
